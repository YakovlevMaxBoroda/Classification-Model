{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# фиксируем для воспроизводимости\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unusual-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь на локальной машине, ссылка на исходный датасет указана в ReadMe\n",
    "root = r'C:\\\\Users\\\\Maxim\\\\Downloads\\\\archive\\\\AdienceBenchmarkGenderAndAgeClassification\\\\' \n",
    "total_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    data = pd.read_csv(root+'fold_{}_data.txt'.format(i), sep = '\\t') # Параметры и лейблы помещены в 5 отдельных txt-файлов, собираем их в один\n",
    "    total_data = total_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rotary-carbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "      <td>19370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1023.858906</td>\n",
       "      <td>949.670212</td>\n",
       "      <td>675.659370</td>\n",
       "      <td>633.042437</td>\n",
       "      <td>629.692463</td>\n",
       "      <td>-12.405111</td>\n",
       "      <td>3.128549</td>\n",
       "      <td>72.266598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>645.385251</td>\n",
       "      <td>667.060150</td>\n",
       "      <td>429.918002</td>\n",
       "      <td>440.409036</td>\n",
       "      <td>426.296233</td>\n",
       "      <td>73.430214</td>\n",
       "      <td>15.658667</td>\n",
       "      <td>38.799247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>-205.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>441.250000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>980.000000</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1526.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>964.000000</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>778.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2284.000000</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>2752.000000</td>\n",
       "      <td>3264.000000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>221.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            face_id             x             y            dx            dy  \\\n",
       "count  19370.000000  19370.000000  19370.000000  19370.000000  19370.000000   \n",
       "mean    1023.858906    949.670212    675.659370    633.042437    629.692463   \n",
       "std      645.385251    667.060150    429.918002    440.409036    426.296233   \n",
       "min        1.000000      0.000000      0.000000     80.000000     80.000000   \n",
       "25%      486.000000    441.250000    333.000000    324.000000    325.000000   \n",
       "50%      980.000000    852.000000    653.000000    517.000000    517.000000   \n",
       "75%     1526.000000   1359.000000    964.000000    778.000000    778.000000   \n",
       "max     2284.000000  10024.000000   2752.000000   3264.000000   3225.000000   \n",
       "\n",
       "           tilt_ang  fiducial_yaw_angle  fiducial_score  \n",
       "count  19370.000000        19370.000000    19370.000000  \n",
       "mean     -12.405111            3.128549       72.266598  \n",
       "std       73.430214           15.658667       38.799247  \n",
       "min     -205.000000          -45.000000        5.000000  \n",
       "25%      -80.000000            0.000000       42.000000  \n",
       "50%       -5.000000            0.000000       70.000000  \n",
       "75%        5.000000            0.000000       98.000000  \n",
       "max      365.000000           45.000000      221.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "great-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10399646885_67c7d20df9_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>-115</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10424815813_e94629b1ec_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>175</td>\n",
       "      <td>-30</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>11816644924_075c3d8d59_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                original_image  face_id       age gender     x  \\\n",
       "0  30601258@N03  10399646885_67c7d20df9_o.jpg        1  (25, 32)      f     0   \n",
       "1  30601258@N03  10424815813_e94629b1ec_o.jpg        2  (25, 32)      m   301   \n",
       "2  30601258@N03  10437979845_5985be4b26_o.jpg        1  (25, 32)      f  2395   \n",
       "3  30601258@N03  10437979845_5985be4b26_o.jpg        3  (25, 32)      m   752   \n",
       "4  30601258@N03  11816644924_075c3d8d59_o.jpg        2  (25, 32)      m   175   \n",
       "\n",
       "      y    dx    dy  tilt_ang  fiducial_yaw_angle  fiducial_score  \n",
       "0   414  1086  1383      -115                  30              17  \n",
       "1   105   640   641         0                   0              94  \n",
       "2   876   771   771       175                 -30              74  \n",
       "3  1255   484   485       180                   0              47  \n",
       "4    80   769   768       -75                   0              34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exact-problem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19370 entries, 0 to 3815\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   user_id             19370 non-null  object\n",
      " 1   original_image      19370 non-null  object\n",
      " 2   face_id             19370 non-null  int64 \n",
      " 3   age                 19370 non-null  object\n",
      " 4   gender              18591 non-null  object\n",
      " 5   x                   19370 non-null  int64 \n",
      " 6   y                   19370 non-null  int64 \n",
      " 7   dx                  19370 non-null  int64 \n",
      " 8   dy                  19370 non-null  int64 \n",
      " 9   tilt_ang            19370 non-null  int64 \n",
      " 10  fiducial_yaw_angle  19370 non-null  int64 \n",
      " 11  fiducial_score      19370 non-null  int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "total_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "herbal-hunger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19370 entries, 0 to 3815\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   age     19370 non-null  object\n",
      " 1   gender  18591 non-null  object\n",
      " 2   x       19370 non-null  int64 \n",
      " 3   y       19370 non-null  int64 \n",
      " 4   dx      19370 non-null  int64 \n",
      " 5   dy      19370 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = total_data[['age', 'gender', 'x', 'y', 'dx', 'dy']].copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessory-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agricultural-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = []\n",
    "for row in total_data.iterrows():\n",
    "    path = 'C:\\\\Users\\\\Maxim\\\\Downloads\\\\archive\\\\AdienceBenchmarkGenderAndAgeClassification\\\\'+'faces\\\\'+row[1].user_id+'\\\\coarse_tilt_aligned_face.'+str(row[1].face_id)+'.'+row[1].original_image\n",
    "    img_path.append(path)\n",
    "\n",
    "df['img_path'] = img_path # добавляем в датафрейм пути к файлам картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wrapped-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем возрастные группы\n",
    "age_mapping = [('(0, 2)', '0-3'), ('2', '0-3'), ('3', '0-3'), ('(4, 6)', '4-6'), \n",
    "               ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-22'), ('(8, 23)','15-22'), \n",
    "               ('23', '25-33'), ('(15, 20)', '15-22'), ('(25, 32)', '25-33'),\n",
    "               ('(27, 32)', '25-33'), ('32', '25-33'), ('34', '25-33'), ('29', '25-33'), \n",
    "               ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '38-43'), \n",
    "               ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), \n",
    "               ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), \n",
    "               ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "standing-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping_dict = {each[0]: each[1] for each in age_mapping} # словарь по возрастным группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparable-victory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Заменяем в исходном датафрейме значения возрастов на сформированные возрастные группы\n",
    "drop_labels = []\n",
    "for idx, each in enumerate(df.age):\n",
    "    if each == 'None':\n",
    "        drop_labels.append(idx)\n",
    "    elif each in age_mapping_dict.keys():\n",
    "        df.age.loc[idx] = age_mapping_dict[each]\n",
    "    else:\n",
    "        drop_labels.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enclosed-diversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "11583    1\n",
       "15677    1\n",
       "13628    1\n",
       "3387     1\n",
       "        ..\n",
       "645      1\n",
       "2692     1\n",
       "12931    1\n",
       "14978    1\n",
       "2047     1\n",
       "Length: 19370, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adjustable-default",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-33    5296\n",
       "38-43    2777\n",
       "0-3      2509\n",
       "8-13     2292\n",
       "4-6      2140\n",
       "15-22    1792\n",
       "48-53     915\n",
       "60+       901\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(index=drop_labels)\n",
    "df.age.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesser-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17452 entries, 0 to 19345\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   index     17452 non-null  int64 \n",
      " 1   age       17452 non-null  object\n",
      " 2   gender    17452 non-null  object\n",
      " 3   x         17452 non-null  int64 \n",
      " 4   y         17452 non-null  int64 \n",
      " 5   dx        17452 non-null  int64 \n",
      " 6   dy        17452 non-null  int64 \n",
      " 7   img_path  17452 non-null  object\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "final_data = df[df.gender != 'u'].copy()\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepting-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_to_label = {'f' : 0, 'm' : 1}\n",
    "\n",
    "age_to_label = {\n",
    "    '0-3'  :0,\n",
    "    '4-6'  :1,\n",
    "    '8-13' :2,\n",
    "    '15-22':3,\n",
    "    '25-33':4,\n",
    "    '38-43':5,\n",
    "    '48-53':6,\n",
    "    '60+'  :7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "younger-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  age  gender     x     y    dx    dy  \\\n",
       "0      0    4       0     0   414  1086  1383   \n",
       "1      1    4       1   301   105   640   641   \n",
       "2      2    4       0  2395   876   771   771   \n",
       "3      3    4       1   752  1255   484   485   \n",
       "4      4    4       1   175    80   769   768   \n",
       "\n",
       "                                            img_path  \n",
       "0  C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...  \n",
       "1  C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...  \n",
       "2  C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...  \n",
       "3  C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...  \n",
       "4  C:\\Users\\Maxim\\Downloads\\archive\\AdienceBenchm...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для дальнейшей работы необходимо присвоить всем группам номера\n",
    "final_data['age'] = final_data['age'].apply(lambda age: age_to_label[age])\n",
    "final_data['gender'] = final_data['gender'].apply(lambda g: gender_to_label[g])\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "figured-belly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9332\n",
       "1    8120\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "curious-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5240\n",
       "5    2777\n",
       "2    2285\n",
       "1    2139\n",
       "3    1790\n",
       "0    1418\n",
       "6     908\n",
       "7     895\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "center-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Делим весь набор данных на train и test\n",
    "train, test = train_test_split(final_data, test_size=0.2, random_state=42, shuffle=True) \n",
    "# фиксируем random_state для вопроизводимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dedicated-trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13961, 8)\n",
      "(3491, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unnecessary-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, width=128, height=128, transform=None, prediction='gender'):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.transform = transform\n",
    "        self.prediction = prediction\n",
    "        self.dataset = dataset\n",
    "        y, x = self.get_dataset() #y - список с лейблами, x - список с путями до файлов картинок\n",
    "        self.y = y\n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.x[index]) # используем готовую бибилиотеку для открытия файлов\n",
    "        img = img.resize((self.width, self.height)) # при необходимости меняем размер исходных картинок \n",
    "        img = img.convert('RGB') #конвертируем в RGB\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "#         data = torch.FloatTensor(img)\n",
    "#         label = torch.FloatTensor(self.y)\n",
    "\n",
    "        img = np.asarray(img).transpose(-1, 0, 1) # pytorch работает с тензорами (количество каналов х ширина х высота), поэтому переставляем размерности\n",
    "        img = torch.from_numpy(np.asarray(img))/255 # создаем тензор-картинку\n",
    "        img = img.float() # тип float(), т.к. веса в модели инициируются типом float32\n",
    "        label = torch.from_numpy(np.asarray(self.y[index])).long() # создаем тензор с лейблами, тип doubleint\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def get_dataset(self):\n",
    "        if self.prediction == 'gender':\n",
    "            return self.dataset.gender.values.tolist(), self.dataset.img_path.values.tolist() \n",
    "        if self.prediction == 'age': \n",
    "            return self.dataset.age.values.tolist(), self.dataset.img_path.values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "shaped-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # размер батча\n",
    "dataset1 = ImageData(dataset = train, width = 256, height = 256, prediction = 'age')\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size, shuffle=True) # загружаем train-датасет в train-даталодер\n",
    "dataset2 = ImageData(dataset = test, width = 256, height = 256, prediction = 'age')\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size, shuffle=False) # загружаем test-датасет в test-даталодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "statewide-childhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873, 219)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "recent-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGenderNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0 = torch.nn.BatchNorm2d(num_features=3)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, padding=0)\n",
    "        self.act1  = torch.nn.ELU()\n",
    "        self.bn1 = torch.nn.BatchNorm2d(num_features=6)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # (256-5+1)/2 = 126*126*6 промежуточные рассчеты размера после слоя\n",
    "       \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        self.act2  = torch.nn.ELU()\n",
    "        self.bn2 = torch.nn.BatchNorm2d(num_features=16)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # (126-5+1)/2 = 61*61*16\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=0, stride=2)\n",
    "        self.act3  = torch.nn.ELU()\n",
    "        self.bn3 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # ((61-5)/2+1)/2 = 14*14*32\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=0)\n",
    "        self.act4  = torch.nn.ELU()\n",
    "        self.bn4 = torch.nn.BatchNorm2d(num_features=32)\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # (14-5+1)/2 = 5*5*32=800 - выходной размер при заданных параметрах\n",
    "        # \n",
    "        if dataset1.prediction == 'gender':\n",
    "            self.fc1   = torch.nn.Linear(32, 2)\n",
    "        elif dataset1.prediction == 'age':\n",
    "            self.fc1   = torch.nn.Linear(32, 8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = torch.mean(x, dim = (2,3)) # усредняем выходную картинку по ширине и высоте, \n",
    "        # это позволит загружать картинки разных размеров и скоратит количество вычислительных операций\n",
    "\n",
    "        x = self.fc1(x) \n",
    "        # softmax не используем, чтобы не нагружать вычислениями\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "grave-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeGenderNet().float()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # если код запускается на машине c GPU, позволит считать модель на GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# датасет не сбалансирован по возрасту, добавим в функцию потерь коэффициенты, учитывающие эту несбалансированность по классам\n",
    "if dataset1.prediction=='gender':\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "elif dataset1.prediction=='age':\n",
    "    weights = torch.tensor([3.7, 2.5, 2.3, 3, 1, 2, 6, 6])\n",
    "    loss = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3.0e-4, weight_decay = 3.0e-5) #алгоритм Adam, L2-регуляризация\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) # каждые 5 эпох уменьшаем learning_rate в 2 раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "popular-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        # в каждой эпохе реализуем train и validation фазы\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_loader\n",
    "                scheduler.step()\n",
    "                model.train()  # для train-фазы ставим модель в train\n",
    "            else:\n",
    "                dataloader = test_loader\n",
    "                model.eval()   # фиксируем модель в фазе валидации \n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloader): # tqdm для визуализации прогресса вычисления одной эпохи\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # зануляем градиенты, чтобы не накапливались\n",
    "                # forward и backward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    # поскольку softmax не использовался, в качествее предсказания класса берем номер нейрона с наибольшим значением\n",
    "                    preds_class = preds.argmax(dim=1)  \n",
    "\n",
    "                    # backward + optimize в фазе train\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # подсчет ошибки и точности для одной эпохи по всем батчам\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader) # делим на количество батчей, чтобы получить усредненную по эпохе ошибку\n",
    "            epoch_acc = running_acc / len(dataloader) # делим на количество батчей, чтобы получить усредненную по эпохе точность\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 873/873 [10:58<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.9471 Acc: 0.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 219/219 [01:17<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.8176 Acc: 0.3102\n",
      "Epoch 1/9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 873/873 [10:25<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7232 Acc: 0.3286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 219/219 [01:22<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.6070 Acc: 0.3467\n",
      "Epoch 2/9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▋                                                                  | 150/873 [01:46<08:45,  1.38it/s]"
     ]
    }
   ],
   "source": [
    "train_model(model, loss, optimizer, scheduler, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
